name: AGX-runner-sanity

# Run this manually from the UI (or push a branch if you prefer)
on: workflow_dispatch

jobs:
  sanity:
    # The job will be picked up only by your self-hosted Jetson/AGX runner
    runs-on: [self-hosted, Linux, ARM64]

    steps:
    # 1) Basic info â€” lets you confirm which machine is executing
    - name: Show runner info
      run: |
        echo "Runner name:    $RUNNER_NAME"
        echo "Runner labels:  $RUNNER_FEATURE"
        echo "OS:             $RUNNER_OS"
        echo "Kernel:         $(uname -a)"

    # 2) Quick Python / PyTorch / CUDA smoke-test
    - name: Python + CUDA test
      run: |
        python - <<'PY'
        import torch, platform, time
        print("Python", platform.python_version())
        print("Torch ", torch.__version__)
        print("CUDA  available:", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("Device count:", torch.cuda.device_count())
            print("Device name:", torch.cuda.get_device_name(0))
            # Do a tiny matmul to exercise the GPU
            a = torch.randn(8192, 1024, device='cuda')
            b = torch.randn(1024, 1024, device='cuda')
            t0 = time.time()
            c = a @ b
            torch.cuda.synchronize()
            print("Matmul finished in %.3f s  (mean=%.4f)" % (time.time()-t0, c.mean().item()))
        PY
